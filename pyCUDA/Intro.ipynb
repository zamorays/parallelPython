{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyCUDA basics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to install, execute in a cell: %install_ext https://raw.github.com/minrk/ipython_extensions/master/nbtoc.py\n",
      "%load_ext nbtoc\n",
      "%nbtoc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<!-- extracted from https://gist.github.com/magican/5574556 -->\n",
        "<div id=\"toc-wrapper\">\n",
        "    <div class=\"header\">Contents <a href=\"#\" class=\"hide-btn\">[hide]</a></div>\n",
        "    <div id=\"toc\"></div>\n",
        "</div>\n",
        " \n",
        "<style>\n",
        "  #toc {\n",
        "    overflow-y: scroll;\n",
        "    max-height: 300px;\n",
        "  }\n",
        "  #toc-wrapper {\n",
        "    position: fixed; top: 120px; max-width:430px; right: 20px;\n",
        "    border: thin solid rgba(0, 0, 0, 0.38); opacity: .8;\n",
        "    border-radius: 5px; background-color: #fff; padding:10px;\n",
        "    z-index: 100;\n",
        "  }\n",
        "  #toc-wrapper.closed {\n",
        "      min-width: 100px;\n",
        "      width: auto;\n",
        "      transition: width;\n",
        "  }\n",
        "  #toc-wrapper:hover{\n",
        "      opacity:1;\n",
        "  }\n",
        "  #toc-wrapper .header {\n",
        "      font-size:18px; font-weight: bold;\n",
        "  }\n",
        "  #toc-wrapper .hide-btn {\n",
        "      font-size: 14px;\n",
        "  }\n",
        " \n",
        "</style>\n",
        "\n",
        "<style>\n",
        "  ol.nested {\n",
        "    counter-reset: item;\n",
        "    list-style: none;\n",
        "  }\n",
        "  li.nested {\n",
        "        display: block;\n",
        "    }\n",
        "  li.nested:before {\n",
        "        counter-increment: item;\n",
        "        content: counters(item, \".\")\" \";\n",
        "    }\n",
        "</style>\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "javascript": [
        "// adapted from https://gist.github.com/magican/5574556\n",
        "\n",
        "function clone_anchor(element) {\n",
        "  // clone link\n",
        "  var h = element.find(\"div.text_cell_render\").find(':header').first();\n",
        "  var a = h.find('a').clone();\n",
        "  var new_a = $(\"<a>\");\n",
        "  new_a.attr(\"href\", a.attr(\"href\"));\n",
        "  // get the text *excluding* the link text, whatever it may be\n",
        "  var hclone = h.clone();\n",
        "  hclone.children().remove();\n",
        "  new_a.text(hclone.text());\n",
        "  return new_a;\n",
        "}\n",
        "\n",
        "function ol_depth(element) {\n",
        "  // get depth of nested ol\n",
        "  var d = 0;\n",
        "  while (element.prop(\"tagName\").toLowerCase() == 'ol') {\n",
        "    d += 1;\n",
        "    element = element.parent();\n",
        "  }\n",
        "  return d;\n",
        "}\n",
        "\n",
        "function table_of_contents(threshold) {\n",
        "  if (threshold === undefined) {\n",
        "    threshold = 4;\n",
        "  }\n",
        "  var cells = IPython.notebook.get_cells();\n",
        "  \n",
        "  var ol = $(\"<ol/>\");\n",
        "  $(\"#toc\").empty().append(ol);\n",
        "  \n",
        "  for (var i=0; i < cells.length; i++) {\n",
        "    var cell = cells[i];\n",
        "    \n",
        "    if (cell.cell_type !== 'heading') continue;\n",
        "    \n",
        "    var level = cell.level;\n",
        "    if (level > threshold) continue;\n",
        "    \n",
        "    var depth = ol_depth(ol);\n",
        "\n",
        "    // walk down levels\n",
        "    for (; depth < level; depth++) {\n",
        "      var new_ol = $(\"<ol/>\");\n",
        "      ol.append(new_ol);\n",
        "      ol = new_ol;\n",
        "    }\n",
        "    // walk up levels\n",
        "    for (; depth > level; depth--) {\n",
        "      ol = ol.parent();\n",
        "    }\n",
        "    //\n",
        "    ol.append(\n",
        "      $(\"<li/>\").append(clone_anchor(cell.element))\n",
        "    );\n",
        "  }\n",
        "\n",
        "  $('#toc-wrapper .header').click(function(){\n",
        "    $('#toc').slideToggle();\n",
        "    $('#toc-wrapper').toggleClass('closed');\n",
        "    if ($('#toc-wrapper').hasClass('closed')){\n",
        "      $('#toc-wrapper .hide-btn').text('[show]');\n",
        "    } else {\n",
        "      $('#toc-wrapper .hide-btn').text('[hide]');\n",
        "    }\n",
        "    return false;\n",
        "  })\n",
        "\n",
        "  $(window).resize(function(){\n",
        "    $('#toc').css({maxHeight: $(window).height() - 200})\n",
        "  })\n",
        "\n",
        "  $(window).trigger('resize')\n",
        "}\n",
        "\n",
        "table_of_contents();\n",
        "\n",
        "\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Versions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%load_ext version_information\n",
      "#%version_information numpy, scipy, matplotlib, sympy, pycuda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]</td></tr><tr><td>IPython</td><td>2.0.0-dev</td></tr><tr><td>OS</td><td>posix [linux2]</td></tr><tr><td>numpy</td><td>1.6.1</td></tr><tr><td>scipy</td><td>0.9.0</td></tr><tr><td>matplotlib</td><td>1.1.1rc</td></tr><tr><td>sympy</td><td>0.7.4-git</td></tr><tr><td>pycuda</td><td>'module' object has no attribute '__version__'</td></tr><tr><td colspan='2'>Tue Jan 28 01:44:44 2014 CST</td></tr></table>"
       ],
       "json": [
        "{ \"Software versions\" : [{ \"module\" : \"Python\", \"version\" : \"2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]\" }, { \"module\" : \"IPython\", \"version\" : \"2.0.0-dev\" }, { \"module\" : \"OS\", \"version\" : \"posix [linux2]\" }, { \"module\" : \"numpy\", \"version\" : \"1.6.1\" }, { \"module\" : \"scipy\", \"version\" : \"0.9.0\" }, { \"module\" : \"matplotlib\", \"version\" : \"1.1.1rc\" }, { \"module\" : \"sympy\", \"version\" : \"0.7.4-git\" }, { \"module\" : \"pycuda\", \"version\" : \"'module' object has no attribute '__version__'\" } ] }"
       ],
       "latex": [
        "\\begin{tabular}{|l|l|}\\hline\n",
        "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
        "Python & 2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3] \\\\ \\hline\n",
        "IPython & 2.0.0-dev \\\\ \\hline\n",
        "OS & posix [linux2] \\\\ \\hline\n",
        "numpy & 1.6.1 \\\\ \\hline\n",
        "scipy & 0.9.0 \\\\ \\hline\n",
        "matplotlib & 1.1.1rc \\\\ \\hline\n",
        "sympy & 0.7.4-git \\\\ \\hline\n",
        "pycuda & 'module' object has no attribute '__version__' \\\\ \\hline\n",
        "\\hline \\multicolumn{2}{|l|}{Tue Jan 28 01:44:44 2014 CST} \\\\ \\hline\n",
        "\\end{tabular}\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Software versions\n",
        "Python 2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]\n",
        "IPython 2.0.0-dev\n",
        "OS posix [linux2]\n",
        "numpy 1.6.1\n",
        "scipy 0.9.0\n",
        "matplotlib 1.1.1rc\n",
        "sympy 0.7.4-git\n",
        "pycuda 'module' object has no attribute '__version__'\n",
        "\n",
        "Tue Jan 28 01:44:44 2014 CST"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycuda.VERSION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(2013, 1, 1)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nvcc --version"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
        "Copyright (c) 2005-2013 NVIDIA Corporation\r\n",
        "Built on Wed_Jul_17_18:36:13_PDT_2013\r\n",
        "Cuda compilation tools, release 5.5, V5.5.0\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring your GPU device."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Listing devices:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pycuda import autoinit\n",
      "from pycuda.tools import DeviceData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "specs = DeviceData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Max threads pero block = ',specs.max_threads"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Max threads pero block =  1024\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Warp size            =',specs.warp_size\n",
      "print 'Warps per MP         =', specs.warps_per_mp\n",
      "print 'Thread Blocks per MP =', specs.thread_blocks_per_mp\n",
      "print 'Registers            =', specs.registers\n",
      "print 'Shared memory        =', specs.shared_memory\n",
      "print 'Granularity ??       =', specs.smem_granularity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Warp size            = 32\n",
        "Warps per MP         = 48\n",
        "Thread Blocks per MP = 8\n",
        "Registers            = 32768\n",
        "Shared memory        = 49152\n",
        "Granularity ??       = 32\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other way"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.driver as drv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drv.init()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drv.get_version()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "(5, 5, 0)"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devn = drv.Device.count()\n",
      "print 'Localized GPUs =',devn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Localized GPUs = 1\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devices = []\n",
      "for i in range(devn):\n",
      "    devices.append(drv.Device(i))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All you want to know about your GPU, but you're afraid to ask!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sp in devices:\n",
      "    print 'Name = ',sp.name()\n",
      "    print 'PCI Bus = ',sp.pci_bus_id()\n",
      "    print 'Compute Capability = ',sp.compute_capability()\n",
      "    print 'Total Memory = ',sp.total_memory()/(2.**20) , 'MBytes'\n",
      "    attr = sp.get_attributes()\n",
      "    for j in range(len(attr.items())):\n",
      "        print attr.items()[j]#,'Bytes (when apply)'\n",
      "    print '------------------'\n",
      "    print '------------------'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Name =  GeForce GTX 570\n",
        "PCI Bus =  0000:01:00.0\n",
        "Compute Capability =  (2, 0)\n",
        "Total Memory =  1279.5625 MBytes\n",
        "(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK, 1024)\n",
        "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_X, 1024)\n",
        "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_Y, 1024)\n",
        "(pycuda._driver.device_attribute.MAX_BLOCK_DIM_Z, 64)\n",
        "(pycuda._driver.device_attribute.MAX_GRID_DIM_X, 65535)\n",
        "(pycuda._driver.device_attribute.MAX_GRID_DIM_Y, 65535)\n",
        "(pycuda._driver.device_attribute.MAX_GRID_DIM_Z, 65535)\n",
        "(pycuda._driver.device_attribute.MAX_SHARED_MEMORY_PER_BLOCK, 49152)\n",
        "(pycuda._driver.device_attribute.TOTAL_CONSTANT_MEMORY, 65536)\n",
        "(pycuda._driver.device_attribute.WARP_SIZE, 32)\n",
        "(pycuda._driver.device_attribute.MAX_PITCH, 2147483647)\n",
        "(pycuda._driver.device_attribute.MAX_REGISTERS_PER_BLOCK, 32768)\n",
        "(pycuda._driver.device_attribute.CLOCK_RATE, 1464000)\n",
        "(pycuda._driver.device_attribute.TEXTURE_ALIGNMENT, 512)\n",
        "(pycuda._driver.device_attribute.GPU_OVERLAP, 1)\n",
        "(pycuda._driver.device_attribute.MULTIPROCESSOR_COUNT, 15)\n",
        "(pycuda._driver.device_attribute.KERNEL_EXEC_TIMEOUT, 1)\n",
        "(pycuda._driver.device_attribute.INTEGRATED, 0)\n",
        "(pycuda._driver.device_attribute.CAN_MAP_HOST_MEMORY, 1)\n",
        "(pycuda._driver.device_attribute.COMPUTE_MODE, pycuda._driver.compute_mode.DEFAULT)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_HEIGHT, 65535)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_WIDTH, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_HEIGHT, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES, 2048)\n",
        "(pycuda._driver.device_attribute.SURFACE_ALIGNMENT, 512)\n",
        "(pycuda._driver.device_attribute.CONCURRENT_KERNELS, 1)\n",
        "(pycuda._driver.device_attribute.ECC_ENABLED, 0)\n",
        "(pycuda._driver.device_attribute.PCI_BUS_ID, 1)\n",
        "(pycuda._driver.device_attribute.PCI_DEVICE_ID, 0)\n",
        "(pycuda._driver.device_attribute.TCC_DRIVER, 0)\n",
        "(pycuda._driver.device_attribute.MEMORY_CLOCK_RATE, 1900000)\n",
        "(pycuda._driver.device_attribute.GLOBAL_MEMORY_BUS_WIDTH, 320)\n",
        "(pycuda._driver.device_attribute.L2_CACHE_SIZE, 655360)\n",
        "(pycuda._driver.device_attribute.MAX_THREADS_PER_MULTIPROCESSOR, 1536)\n",
        "(pycuda._driver.device_attribute.ASYNC_ENGINE_COUNT, 1)\n",
        "(pycuda._driver.device_attribute.UNIFIED_ADDRESSING, 1)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_WIDTH, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LAYERED_LAYERS, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_WIDTH, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_GATHER_HEIGHT, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE, 0)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE, 0)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE, 0)\n",
        "(pycuda._driver.device_attribute.PCI_DOMAIN_ID, 0)\n",
        "(pycuda._driver.device_attribute.TEXTURE_PITCH_ALIGNMENT, 32)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_WIDTH, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH, 16384)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS, 2046)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_HEIGHT, 32768)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_HEIGHT, 32768)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE3D_DEPTH, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE1D_LAYERED_LAYERS, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_WIDTH, 65536)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_HEIGHT, 32768)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACE2D_LAYERED_LAYERS, 2048)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_WIDTH, 32768)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH, 32768)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS, 2046)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE1D_LINEAR_WIDTH, 134217728)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_WIDTH, 65000)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_HEIGHT, 65000)\n",
        "(pycuda._driver.device_attribute.MAXIMUM_TEXTURE2D_LINEAR_PITCH, 1048544)\n",
        "------------------\n",
        "------------------\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MAX_THREADS_PER_BLOCK, 1024\n",
      "\n",
      "For example for a 3D mesh (less optimal), we only have avaiable $$8\\times 8\\times 8 = 512 \\,simetric$$ \n",
      " $$8\\times 8\\times 16 = 1024 \\,cilindrical$$\n",
      "block size per dimension = 8 or 16.\n",
      "In 2D case the optimal value is:\n",
      "$$32\\times32 = 1024$$\n",
      "In last case $$1024$$\n",
      "\n",
      "\n",
      "MAX_THREADS_PER_MULTIPROCESSOR, $1536 = 3*2^9$\n",
      "\n",
      "If we can take this literally, we can process in one processor about 3 meshes of $8\\times8\\times8$, or three blocks of 3D meshes. With this result, we can evaluate the eficience comparing cilindrical and simetric performance\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now your device has .."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "drv.mem_get_info()[0]/(2.**20),'MB of Free Memory',drv.mem_get_info()[1]/(2.**20),'MB Total Memory'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "(987.2421875, 'MB of Free Memory', 1279.5625, 'MB Total Memory')"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's think in array sizes. For example a float of 4 bytes length:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Linear max:', drv.mem_get_info()[0]/(4*8)\n",
      "print '2D max:', np.sqrt(drv.mem_get_info()[0]/(4*8))\n",
      "print '3D max:', np.power(drv.mem_get_info()[0]/(4*8),1./3.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Linear max: 32349952\n",
        "2D max: 5687.7018206\n",
        "3D max: 318.633338212\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "GPU-ARRAY STRUCTURE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycuda.gpuarray as gpuarray"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.random.rand(10,20,30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(10, 20, 30)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu = gpuarray.to_gpu(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.gpudata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<pycuda._driver.DeviceAllocation at 0x4c25280>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psi1_h = np.zeros( (1,10,100), dtype=np.complex64)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psi1_h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "array([[[ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j],\n",
        "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,  0.+0.j,\n",
        "          0.+0.j,  0.+0.j]]], dtype=complex64)"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b=psi1_h.real"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "array([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
        "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
        "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    }
   ],
   "metadata": {}
  }
 ]
}