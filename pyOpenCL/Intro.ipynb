{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyOpenCL basics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to install, execute in a cell: %install_ext https://raw.github.com/minrk/ipython_extensions/master/nbtoc.py\n",
      "# Optional for index view\n",
      "%load_ext nbtoc\n",
      "%nbtoc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<!-- extracted from https://gist.github.com/magican/5574556 -->\n",
        "<div id=\"toc-wrapper\">\n",
        "    <div class=\"header\">Contents <a href=\"#\" class=\"hide-btn\">[hide]</a></div>\n",
        "    <div id=\"toc\"></div>\n",
        "</div>\n",
        " \n",
        "<style>\n",
        "  #toc {\n",
        "    overflow-y: scroll;\n",
        "    max-height: 300px;\n",
        "  }\n",
        "  #toc-wrapper {\n",
        "    position: fixed; top: 120px; max-width:430px; right: 20px;\n",
        "    border: thin solid rgba(0, 0, 0, 0.38); opacity: .8;\n",
        "    border-radius: 5px; background-color: #fff; padding:10px;\n",
        "    z-index: 100;\n",
        "  }\n",
        "  #toc-wrapper.closed {\n",
        "      min-width: 100px;\n",
        "      width: auto;\n",
        "      transition: width;\n",
        "  }\n",
        "  #toc-wrapper:hover{\n",
        "      opacity:1;\n",
        "  }\n",
        "  #toc-wrapper .header {\n",
        "      font-size:18px; font-weight: bold;\n",
        "  }\n",
        "  #toc-wrapper .hide-btn {\n",
        "      font-size: 14px;\n",
        "  }\n",
        " \n",
        "</style>\n",
        "\n",
        "<style>\n",
        "  ol.nested {\n",
        "    counter-reset: item;\n",
        "    list-style: none;\n",
        "  }\n",
        "  li.nested {\n",
        "        display: block;\n",
        "    }\n",
        "  li.nested:before {\n",
        "        counter-increment: item;\n",
        "        content: counters(item, \".\")\" \";\n",
        "    }\n",
        "</style>\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "javascript": [
        "// adapted from https://gist.github.com/magican/5574556\n",
        "\n",
        "function clone_anchor(element) {\n",
        "  // clone link\n",
        "  var h = element.find(\"div.text_cell_render\").find(':header').first();\n",
        "  var a = h.find('a').clone();\n",
        "  var new_a = $(\"<a>\");\n",
        "  new_a.attr(\"href\", a.attr(\"href\"));\n",
        "  // get the text *excluding* the link text, whatever it may be\n",
        "  var hclone = h.clone();\n",
        "  hclone.children().remove();\n",
        "  new_a.text(hclone.text());\n",
        "  return new_a;\n",
        "}\n",
        "\n",
        "function ol_depth(element) {\n",
        "  // get depth of nested ol\n",
        "  var d = 0;\n",
        "  while (element.prop(\"tagName\").toLowerCase() == 'ol') {\n",
        "    d += 1;\n",
        "    element = element.parent();\n",
        "  }\n",
        "  return d;\n",
        "}\n",
        "\n",
        "function table_of_contents(threshold) {\n",
        "  if (threshold === undefined) {\n",
        "    threshold = 4;\n",
        "  }\n",
        "  var cells = IPython.notebook.get_cells();\n",
        "  \n",
        "  var ol = $(\"<ol/>\");\n",
        "  $(\"#toc\").empty().append(ol);\n",
        "  \n",
        "  for (var i=0; i < cells.length; i++) {\n",
        "    var cell = cells[i];\n",
        "    \n",
        "    if (cell.cell_type !== 'heading') continue;\n",
        "    \n",
        "    var level = cell.level;\n",
        "    if (level > threshold) continue;\n",
        "    \n",
        "    var depth = ol_depth(ol);\n",
        "\n",
        "    // walk down levels\n",
        "    for (; depth < level; depth++) {\n",
        "      var new_ol = $(\"<ol/>\");\n",
        "      ol.append(new_ol);\n",
        "      ol = new_ol;\n",
        "    }\n",
        "    // walk up levels\n",
        "    for (; depth > level; depth--) {\n",
        "      ol = ol.parent();\n",
        "    }\n",
        "    //\n",
        "    ol.append(\n",
        "      $(\"<li/>\").append(clone_anchor(cell.element))\n",
        "    );\n",
        "  }\n",
        "\n",
        "  $('#toc-wrapper .header').click(function(){\n",
        "    $('#toc').slideToggle();\n",
        "    $('#toc-wrapper').toggleClass('closed');\n",
        "    if ($('#toc-wrapper').hasClass('closed')){\n",
        "      $('#toc-wrapper .hide-btn').text('[show]');\n",
        "    } else {\n",
        "      $('#toc-wrapper .hide-btn').text('[hide]');\n",
        "    }\n",
        "    return false;\n",
        "  })\n",
        "\n",
        "  $(window).resize(function(){\n",
        "    $('#toc').css({maxHeight: $(window).height() - 200})\n",
        "  })\n",
        "\n",
        "  $(window).trigger('resize')\n",
        "}\n",
        "\n",
        "table_of_contents();\n",
        "\n",
        "\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Versions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext version_information\n",
      "%version_information numpy, scipy, matplotlib, sympy, pyopencl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]</td></tr><tr><td>IPython</td><td>1.0.0</td></tr><tr><td>OS</td><td>posix [linux2]</td></tr><tr><td>numpy</td><td>1.5.1</td></tr><tr><td>scipy</td><td>0.9.0</td></tr><tr><td>matplotlib</td><td>1.0.1</td></tr><tr><td>sympy</td><td>0.6.7</td></tr><tr><td>pyopencl</td><td>'module' object has no attribute '__version__'</td></tr><tr><td colspan='2'>Tue Oct 15 17:02:55 2013 CDT</td></tr></table>"
       ],
       "json": [
        "{ \"Software versions\" : [{ \"module\" : \"Python\", \"version\" : \"2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]\" }, { \"module\" : \"IPython\", \"version\" : \"1.0.0\" }, { \"module\" : \"OS\", \"version\" : \"posix [linux2]\" }, { \"module\" : \"numpy\", \"version\" : \"1.5.1\" }, { \"module\" : \"scipy\", \"version\" : \"0.9.0\" }, { \"module\" : \"matplotlib\", \"version\" : \"1.0.1\" }, { \"module\" : \"sympy\", \"version\" : \"0.6.7\" }, { \"module\" : \"pyopencl\", \"version\" : \"'module' object has no attribute '__version__'\" } ] }"
       ],
       "latex": [
        "\\begin{tabular}{|l|l|}\\hline\n",
        "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
        "Python & 2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1] \\\\ \\hline\n",
        "IPython & 1.0.0 \\\\ \\hline\n",
        "OS & posix [linux2] \\\\ \\hline\n",
        "numpy & 1.5.1 \\\\ \\hline\n",
        "scipy & 0.9.0 \\\\ \\hline\n",
        "matplotlib & 1.0.1 \\\\ \\hline\n",
        "sympy & 0.6.7 \\\\ \\hline\n",
        "pyopencl & 'module' object has no attribute '__version__' \\\\ \\hline\n",
        "\\hline \\multicolumn{2}{|l|}{Tue Oct 15 17:02:55 2013 CDT} \\\\ \\hline\n",
        "\\end{tabular}\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Software versions\n",
        "Python 2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]\n",
        "IPython 1.0.0\n",
        "OS posix [linux2]\n",
        "numpy 1.5.1\n",
        "scipy 0.9.0\n",
        "matplotlib 1.0.1\n",
        "sympy 0.6.7\n",
        "pyopencl 'module' object has no attribute '__version__'\n",
        "\n",
        "Tue Oct 15 17:02:55 2013 CDT"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as pycl\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.VERSION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "(2013, 1)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vCL = pycl.get_cl_header_version()\n",
      "print \"OpenCL version {}.{}\".format(vCL[0],vCL[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OpenCL version 1.1\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring your GPU device."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms = pycl.get_platforms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs = []\n",
      "for pl in platforms:\n",
      "    print pl.name\n",
      "    print pl.version\n",
      "    print pl.vendor\n",
      "    print pl.extensions\n",
      "    print pl.profile\n",
      "    print '______________'\n",
      "    print '              '\n",
      "    devs.append(pl.get_devices()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NVIDIA CUDA\n",
        "OpenCL 1.1 CUDA 4.2.1\n",
        "NVIDIA Corporation\n",
        "cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll \n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n",
        "AMD Accelerated Parallel Processing\n",
        "OpenCL 1.2 AMD-APP (1113.2)\n",
        "Advanced Micro Devices, Inc.\n",
        "cl_khr_icd cl_amd_event_callback cl_amd_offline_devices\n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=devs[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.platform.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'NVIDIA CUDA'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devices and properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for device in devs:\n",
      "        print(\"---------------------------------------------------------------\")\n",
      "        print(\"Device name:\", device.name)\n",
      "        print(\"Device type:\", pycl.device_type.to_string(device.type))\n",
      "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
      "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
      "        print(\"Device compute units:\", device.max_compute_units)\n",
      "        print(\"Device max work group size:\", device.max_work_group_size)\n",
      "        if device.platform.name =='NVIDIA CUDA':\n",
      "            print(\"Device warp size:\", device.warp_size_nv)\n",
      "        print(\"====== IMAGE ======\")\n",
      "        print('Device image support:', device.image_support)\n",
      "        print('Device image 2D max dimensions: [', device.image2d_max_height,',',device.image2d_max_width,']')\n",
      "        print('Device image 3D max dimensions: [', device.image3d_max_height,',',device.image3d_max_width,',',device.image3d_max_depth,']')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---------------------------------------------------------------\n",
        "('Device name:', 'GeForce GTX 670')\n",
        "('Device type:', 'GPU')\n",
        "('Device memory: ', 2047, 'MB')\n",
        "('Device max clock speed:', 980, 'MHz')\n",
        "('Device compute units:', 7)\n",
        "('Device max work group size:', 1024)\n",
        "('Device warp size:', 32)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 32768, ',', 32768, ']')\n",
        "('Device image 3D max dimensions: [', 4096, ',', 4096, ',', 4096, ']')\n",
        "---------------------------------------------------------------\n",
        "('Device name:', 'AMD FX(tm)-8150 Eight-Core Processor           ')\n",
        "('Device type:', 'CPU')\n",
        "('Device memory: ', 7983, 'MB')\n",
        "('Device max clock speed:', 3600, 'MHz')\n",
        "('Device compute units:', 8)\n",
        "('Device max work group size:', 1024)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 8192, ',', 8192, ']')\n",
        "('Device image 3D max dimensions: [', 2048, ',', 2048, ',', 2048, ']')\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs[0].double_fp_config"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "63"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Default Context and Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Default Context**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctx = pycl.create_some_context()\n",
      "queue = pycl.CommandQueue(ctx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Choose platform:\n",
        "[0] <pyopencl.Platform 'NVIDIA CUDA' at 0x2f07ec0>\n",
        "[1] <pyopencl.Platform 'AMD Accelerated Parallel Processing' at 0x7fa9f11074e0>\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtype = np.float32\n",
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl.array as cl_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These alredy in GPU Device (Default: device = 0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu = cl_array.to_device(queue, np.random.rand(N).astype(dtype))\n",
      "b_gpu = cl_array.to_device(queue, np.ones(N).astype(dtype))\n",
      "c_gpu = cl_array.to_device(queue, np.zeros(N).astype(dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  \u00b4a_gpu\u00b4 is a special data struct that manage numpy type array in the Device. This is a powerful tool shuch as we can use these structures as the classic numpy case (formally these data is a map in the DEVICE). This data structure is called ARRAY and is different from the linear mem alloc of OpenCL."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Array properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Classic print: ',a_gpu\n",
      "print 'Context own  : ',a_gpu.context.devices\n",
      "print 'Data struct  : ',a_gpu.data\n",
      "print 'Kernel dims? : ',a_gpu.get_sizes(queue)\n",
      "print 'Type         : ',a_gpu.dtype\n",
      "print 'Size (Bytes) : ',a_gpu.nbytes\n",
      "print 'Length       : ',a_gpu.size\n",
      "print 'Shape        : ',a_gpu.shape\n",
      "print 'Show astype  : ',a_gpu.view(dtype=np.int16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classic print:  [ 0.80243254  0.02072567  0.7784636   0.92119086  0.91816324  0.73449802\n",
        "  0.71854913  0.1234441   0.80886799  0.75836384]\n",
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x39dc0b0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x3c270a8>\n",
        "Kernel dims? :  ((32,), (32,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40\n",
        "Length       :  10\n",
        "Shape        :  (10,)\n",
        "Show astype  :  [ 27704  16205 -14113  15529  18788  16199 -11478  16235   3263  16235\n",
        "   2064  16188  -3370  16183 -12221  15868   4601  16207   9250  16194]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This class of array structures in DEVICE have many operation ready for use (All in parallel optimized)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(a_gpu+b_gpu).view() #works as print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "array([ 1.80243254,  1.02072561,  1.7784636 ,  1.92119086,  1.9181633 ,\n",
        "        1.73449802,  1.71854913,  1.12344408,  1.80886793,  1.75836384], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu = a_gpu*b_gpu #direct asignation between arrays"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print c_gpu, a_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.80243254  0.02072567  0.7784636   0.92119086  0.91816324  0.73449802\n",
        "  0.71854913  0.1234441   0.80886799  0.75836384] [ 0.80243254  0.02072567  0.7784636   0.92119086  0.91816324  0.73449802\n",
        "  0.71854913  0.1234441   0.80886799  0.75836384]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert (c_gpu.get()).all() == (a_gpu.get()).all() #get to evaluate the boolen in HOST"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.characterize.usable_local_mem_size(devs[0], nargs=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "49152"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More dimension!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_gpu = cl_array.to_device(queue, np.ones([N,N,N,N]).astype(dtype))\n",
      "e_gpu = cl_array.to_device(queue, np.random.rand(N*N*N*N).astype(dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print 'Classic print: ',d_gpu\n",
      "print 'Context own  : ',d_gpu.context.devices\n",
      "print 'Data struct  : ',d_gpu.data\n",
      "print 'Kernel dims? : ',d_gpu.get_sizes(queue)\n",
      "print 'Type         : ',d_gpu.dtype\n",
      "print 'Size (Bytes) : ',d_gpu.nbytes\n",
      "print 'Length       : ',d_gpu.size\n",
      "print 'Shape        : ',d_gpu.shape\n",
      "#print 'Show astype  : ',d_gpu.view(dtype=np.int16) #may not func poperly?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x39dc0b0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x3cec890>\n",
        "Kernel dims? :  ((14336,), (64,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40000\n",
        "Length       :  10000\n",
        "Shape        :  (10, 10, 10, 10)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e_gpu=e_gpu.reshape([N,N,N,N])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Context own  : ',e_gpu.context.devices\n",
      "print 'Data struct  : ',e_gpu.data\n",
      "print 'Kernel dims? : ',e_gpu.get_sizes(queue)\n",
      "print 'Type         : ',e_gpu.dtype\n",
      "print 'Size (Bytes) : ',e_gpu.nbytes\n",
      "print 'Length       : ',e_gpu.size\n",
      "print 'Shape        : ',e_gpu.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x39dc0b0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x3cec8e8>\n",
        "Kernel dims? :  ((14336,), (64,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40000\n",
        "Length       :  10000\n",
        "Shape        :  (10, 10, 10, 10)\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other form of constructing arrays"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "other_gpu = cl_array.zeros_like(a_gpu)\n",
      "other_gpu = cl_array.empty_like(a_gpu)\n",
      "other2_gpu = cl_array.arange(queue,1.,10.,0.5,dtype=dtype)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "other2_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([ 1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,  6. ,\n",
        "        6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Array math implemented"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**REDUCTIONS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = pycl.array.sum(d_gpu).get() # Get function copy data to HOST\n",
      "result_gpu = pycl.array.sum(e_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(result),result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "(numpy.ndarray, array(10000.0, dtype=float32))"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(result_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "pyopencl.array.Array"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.array.dot(e_gpu,d_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "array(5028.064453125, dtype=float32)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pycl.array.min(e_gpu).get()\n",
      "print pycl.array.max(e_gpu).get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4.9192483857e-05\n",
        "0.999903559685"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**FUNCTIONS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyopencl import clmath "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clmath.cos(a_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "array([ 0.69495964,  0.99978524,  0.71199322,  0.60487229,  0.60728043,\n",
        "        0.74216723,  0.7527616 ,  0.99239045,  0.69031787,  0.72596222], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clmath.sqrt(a_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ 0.89578593,  0.14396411,  0.88230592,  0.95978695,  0.95820832,\n",
        "        0.8570286 ,  0.84767276,  0.35134614,  0.89937097,  0.87084085], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**KERNELS**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Making context"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}