{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyOpenCL basics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%install_ext https://github.com/dpsanders/ipython_extensions/tree/master/section_numbering\n",
      "#%load_ext secnum\n",
      "#%secnum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to install, execute in a cell: \n",
      "#%install_ext https://raw.github.com/minrk/ipython_extensions/master/nbtoc.py\n",
      "# Optional for index view\n",
      "#%load_ext nbtoc\n",
      "#%nbtoc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Versions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%install_ext http://raw.github.com/jrjohansson/version_information/master/version_information.py\n",
      "%load_ext version_information\n",
      "%version_information numpy, scipy, matplotlib, sympy, pyopencl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]</td></tr><tr><td>IPython</td><td>2.0.0-dev</td></tr><tr><td>OS</td><td>posix [linux2]</td></tr><tr><td>numpy</td><td>1.8.0</td></tr><tr><td>scipy</td><td>0.13.2</td></tr><tr><td>matplotlib</td><td>1.1.1</td></tr><tr><td>sympy</td><td>0.7.4.1</td></tr><tr><td>pyopencl</td><td>2013.3</td></tr><tr><td colspan='2'>Thu Jan 30 20:14:24 2014 CST</td></tr></table>"
       ],
       "json": [
        "{\"Software versions\": [{\"version\": \"2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]\", \"module\": \"Python\"}, {\"version\": \"2.0.0-dev\", \"module\": \"IPython\"}, {\"version\": \"posix [linux2]\", \"module\": \"OS\"}, {\"version\": \"1.8.0\", \"module\": \"numpy\"}, {\"version\": \"0.13.2\", \"module\": \"scipy\"}, {\"version\": \"1.1.1\", \"module\": \"matplotlib\"}, {\"version\": \"0.7.4.1\", \"module\": \"sympy\"}, {\"version\": \"2013.3\", \"module\": \"pyopencl\"}]}"
       ],
       "latex": [
        "\\begin{tabular}{|l|l|}\\hline\n",
        "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
        "Python & 2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3] \\\\ \\hline\n",
        "IPython & 2.0.0-dev \\\\ \\hline\n",
        "OS & posix [linux2] \\\\ \\hline\n",
        "numpy & 1.8.0 \\\\ \\hline\n",
        "scipy & 0.13.2 \\\\ \\hline\n",
        "matplotlib & 1.1.1 \\\\ \\hline\n",
        "sympy & 0.7.4.1 \\\\ \\hline\n",
        "pyopencl & 2013.3 \\\\ \\hline\n",
        "\\hline \\multicolumn{2}{|l|}{Thu Jan 30 20:14:24 2014 CST} \\\\ \\hline\n",
        "\\end{tabular}\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "Software versions\n",
        "Python 2.7.3 (default, Sep 26 2013, 20:03:06) [GCC 4.6.3]\n",
        "IPython 2.0.0-dev\n",
        "OS posix [linux2]\n",
        "numpy 1.8.0\n",
        "scipy 0.13.2\n",
        "matplotlib 1.1.1\n",
        "sympy 0.7.4.1\n",
        "pyopencl 2013.3\n",
        "\n",
        "Thu Jan 30 20:14:24 2014 CST"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as pycl\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.VERSION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(2013, 3)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vCL = pycl.get_cl_header_version()\n",
      "print \"OpenCL version {}.{}\".format(vCL[0],vCL[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OpenCL version 1.1\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring your GPU device."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms = pycl.get_platforms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print platforms"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<pyopencl.Platform 'AMD Accelerated Parallel Processing' at 0x7fc887e96fc0>, <pyopencl.Platform 'NVIDIA CUDA' at 0x437b670>]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plCUDA = platforms[1]\n",
      "plAMD  = platforms[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devCL = plAMD.get_devices()\n",
      "devCU = plCUDA.get_devices()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devCL, devCU"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "([<pyopencl.Device 'AMD FX(tm)-8150 Eight-Core Processor' on 'AMD Accelerated Parallel Processing' at 0x4c378f0>],\n",
        " [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x43c5fb0>])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs = []\n",
      "for pl in platforms:\n",
      "    print pl.name\n",
      "    print pl.version\n",
      "    print pl.vendor\n",
      "    print pl.extensions\n",
      "    print pl.profile\n",
      "    print '______________'\n",
      "    print '              '\n",
      "    devs.append(pl.get_devices()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AMD Accelerated Parallel Processing\n",
        "OpenCL 1.2 AMD-APP (1214.3)\n",
        "Advanced Micro Devices, Inc.\n",
        "cl_khr_icd cl_amd_event_callback cl_amd_offline_devices\n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n",
        "NVIDIA CUDA\n",
        "OpenCL 1.1 CUDA 4.2.1\n",
        "NVIDIA Corporation\n",
        "cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll \n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[<pyopencl.Device 'AMD FX(tm)-8150 Eight-Core Processor' on 'AMD Accelerated Parallel Processing' at 0x4c378f0>,\n",
        " <pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x43c5fb0>]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=devs[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.platform.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "'NVIDIA CUDA'"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devices and properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for device in devs:\n",
      "        print(\"---------------------------------------------------------------\")\n",
      "        print(\"Device name:\", device.name)\n",
      "        print(\"Device type:\", pycl.device_type.to_string(device.type))\n",
      "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
      "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
      "        print(\"Device compute units:\", device.max_compute_units)\n",
      "        print(\"Device max work group size:\", device.max_work_group_size)\n",
      "        if device.platform.name =='NVIDIA CUDA':\n",
      "            print(\"Device warp size:\", device.warp_size_nv)\n",
      "        print(\"====== IMAGE ======\")\n",
      "        print('Device image support:', device.image_support)\n",
      "        print('Device image 2D max dimensions: [', device.image2d_max_height,',',device.image2d_max_width,']')\n",
      "        print('Device image 3D max dimensions: [', device.image3d_max_height,',',device.image3d_max_width,',',device.image3d_max_depth,']')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---------------------------------------------------------------\n",
        "('Device name:', 'AMD FX(tm)-8150 Eight-Core Processor')\n",
        "('Device type:', 'CPU')\n",
        "('Device memory: ', 7967, 'MB')\n",
        "('Device max clock speed:', 1400, 'MHz')\n",
        "('Device compute units:', 8)\n",
        "('Device max work group size:', 1024)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 8192, ',', 8192, ']')\n",
        "('Device image 3D max dimensions: [', 2048, ',', 2048, ',', 2048, ']')\n",
        "---------------------------------------------------------------\n",
        "('Device name:', 'GeForce GTX 670')\n",
        "('Device type:', 'GPU')\n",
        "('Device memory: ', 2047, 'MB')\n",
        "('Device max clock speed:', 980, 'MHz')\n",
        "('Device compute units:', 7)\n",
        "('Device max work group size:', 1024)\n",
        "('Device warp size:', 32)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 32768, ',', 32768, ']')\n",
        "('Device image 3D max dimensions: [', 4096, ',', 4096, ',', 4096, ']')\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs[0].double_fp_config"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "63"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Default Context and Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Default Context**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctx = pycl.Context(devCU)\n",
      "queue = pycl.CommandQueue(ctx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctx = pycl.Context"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctx = pycl.create_some_context"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtype = np.float32\n",
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl.array as cl_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These alredy in GPU Device (Default: device = 0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu = cl_array.to_device(queue, np.random.rand(N).astype(dtype))\n",
      "b_gpu = cl_array.to_device(queue, np.ones(N).astype(dtype))\n",
      "c_gpu = cl_array.to_device(queue, np.zeros(N).astype(dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  \u00b4a_gpu\u00b4 is a special data struct that manage numpy type array in the Device. This is a powerful tool shuch as we can use these structures as the classic numpy case (formally these data is a map in the DEVICE). This data structure is called ARRAY and is different from the linear mem alloc of OpenCL."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Array properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Classic print: ',a_gpu\n",
      "print 'Context own  : ',a_gpu.context.devices\n",
      "print 'Data struct  : ',a_gpu.data\n",
      "print 'Kernel dims? : ',a_gpu.get_sizes(queue)\n",
      "print 'Type         : ',a_gpu.dtype\n",
      "print 'Size (Bytes) : ',a_gpu.nbytes\n",
      "print 'Length       : ',a_gpu.size\n",
      "print 'Shape        : ',a_gpu.shape\n",
      "print 'Show astype  : ',a_gpu.view(dtype=np.int16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Classic print:  [ 0.51278794  0.81855023  0.85562992  0.44863847  0.80100685  0.71678263\n",
        "  0.49334842  0.09523456  0.42369288  0.41009459]\n",
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x43c5fb0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x4deb5d0>\n",
        "Kernel dims? :  ((32,), (32,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40\n",
        "Length       :  10\n",
        "Shape        :  (10,)\n",
        "Show astype  :  [ 17938  16131 -29566  16209   2704  16219 -19471  16101   3785  16205\n",
        "  32529  16183 -26582  16124   2646  15811  -4538  16088  -2069  16081]\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This class of array structures in DEVICE have many operation ready for use (All in parallel optimized)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(a_gpu+b_gpu).view() #works as print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "array([ 1.51278794,  1.81855023,  1.85562992,  1.44863844,  1.80100679,\n",
        "        1.71678257,  1.49334836,  1.09523451,  1.42369294,  1.41009462], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_gpu = a_gpu*b_gpu #direct asignation between arrays"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print c_gpu, a_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.51278794  0.81855023  0.85562992  0.44863847  0.80100685  0.71678263\n",
        "  0.49334842  0.09523456  0.42369288  0.41009459] [ 0.51278794  0.81855023  0.85562992  0.44863847  0.80100685  0.71678263\n",
        "  0.49334842  0.09523456  0.42369288  0.41009459]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert (c_gpu.get()).all() == (a_gpu.get()).all() #get to evaluate the boolen in HOST"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.characterize.usable_local_mem_size(devs[0], nargs=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "32768"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More dimension!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_gpu = cl_array.to_device(queue, np.ones([N,N,N,N]).astype(dtype))\n",
      "e_gpu = cl_array.to_device(queue, np.random.rand(N*N*N*N).astype(dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print 'Classic print: ',d_gpu\n",
      "print 'Context own  : ',d_gpu.context.devices\n",
      "print 'Data struct  : ',d_gpu.data\n",
      "print 'Kernel dims? : ',d_gpu.get_sizes(queue)\n",
      "print 'Type         : ',d_gpu.dtype\n",
      "print 'Size (Bytes) : ',d_gpu.nbytes\n",
      "print 'Length       : ',d_gpu.size\n",
      "print 'Shape        : ',d_gpu.shape\n",
      "#print 'Show astype  : ',d_gpu.view(dtype=np.int16) #may not func poperly?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x43c5fb0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x4e4c520>\n",
        "Kernel dims? :  ((14336,), (64,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40000\n",
        "Length       :  10000\n",
        "Shape        :  (10, 10, 10, 10)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e_gpu=e_gpu.reshape([N,N,N,N])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Context own  : ',e_gpu.context.devices\n",
      "print 'Data struct  : ',e_gpu.data\n",
      "print 'Kernel dims? : ',e_gpu.get_sizes(queue)\n",
      "print 'Type         : ',e_gpu.dtype\n",
      "print 'Size (Bytes) : ',e_gpu.nbytes\n",
      "print 'Length       : ',e_gpu.size\n",
      "print 'Shape        : ',e_gpu.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Context own  :  [<pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x43c5fb0>]\n",
        "Data struct  :  <pyopencl._cl.Buffer object at 0x4e4c578>\n",
        "Kernel dims? :  ((14336,), (64,))\n",
        "Type         :  float32\n",
        "Size (Bytes) :  40000\n",
        "Length       :  10000\n",
        "Shape        :  (10, 10, 10, 10)\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other form of constructing arrays"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "other_gpu = cl_array.zeros_like(a_gpu)\n",
      "other_gpu = cl_array.empty_like(a_gpu)\n",
      "other2_gpu = cl_array.arange(queue,1.,10.,0.5,dtype=dtype)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "other2_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "array([ 1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,  5.5,  6. ,\n",
        "        6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Array math implemented"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**REDUCTIONS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = pycl.array.sum(d_gpu).get() # Get function copy data to HOST\n",
      "result_gpu = pycl.array.sum(e_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(result),result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "(numpy.ndarray, array(10000.0, dtype=float32))"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(result_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "pyopencl.array.Array"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.array.dot(e_gpu,d_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "array(5010.712890625, dtype=float32)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print pycl.array.min(e_gpu).get()\n",
      "print pycl.array.max(e_gpu).get()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000145948026329\n",
        "0.999930500984\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**FUNCTIONS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyopencl import clmath "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clmath.cos(a_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "array([ 0.87138009,  0.68328047,  0.65574306,  0.90103847,  0.69598407,\n",
        "        0.7539233 ,  0.88075209,  0.99546862,  0.91157693,  0.91708314], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clmath.sqrt(a_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "array([ 0.71609217,  0.90473765,  0.92500269,  0.66980481,  0.89498979,\n",
        "        0.84663016,  0.70238763,  0.30860096,  0.65091693,  0.64038628], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**KERNELS**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    }
   ],
   "metadata": {}
  }
 ]
}