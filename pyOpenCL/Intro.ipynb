{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "PyOpenCL basics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to install, execute in a cell: %install_ext https://raw.github.com/minrk/ipython_extensions/master/nbtoc.py\n",
      "%load_ext nbtoc\n",
      "%nbtoc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The nbtoc extension is already loaded. To reload it, use:\n",
        "  %reload_ext nbtoc\n"
       ]
      },
      {
       "html": [
        "<!-- extracted from https://gist.github.com/magican/5574556 -->\n",
        "<div id=\"toc-wrapper\">\n",
        "    <div class=\"header\">Contents <a href=\"#\" class=\"hide-btn\">[hide]</a></div>\n",
        "    <div id=\"toc\"></div>\n",
        "</div>\n",
        " \n",
        "<style>\n",
        "  #toc {\n",
        "    overflow-y: scroll;\n",
        "    max-height: 300px;\n",
        "  }\n",
        "  #toc-wrapper {\n",
        "    position: fixed; top: 120px; max-width:430px; right: 20px;\n",
        "    border: thin solid rgba(0, 0, 0, 0.38); opacity: .8;\n",
        "    border-radius: 5px; background-color: #fff; padding:10px;\n",
        "    z-index: 100;\n",
        "  }\n",
        "  #toc-wrapper.closed {\n",
        "      min-width: 100px;\n",
        "      width: auto;\n",
        "      transition: width;\n",
        "  }\n",
        "  #toc-wrapper:hover{\n",
        "      opacity:1;\n",
        "  }\n",
        "  #toc-wrapper .header {\n",
        "      font-size:18px; font-weight: bold;\n",
        "  }\n",
        "  #toc-wrapper .hide-btn {\n",
        "      font-size: 14px;\n",
        "  }\n",
        " \n",
        "</style>\n",
        "\n",
        "<style>\n",
        "  ol.nested {\n",
        "    counter-reset: item;\n",
        "    list-style: none;\n",
        "  }\n",
        "  li.nested {\n",
        "        display: block;\n",
        "    }\n",
        "  li.nested:before {\n",
        "        counter-increment: item;\n",
        "        content: counters(item, \".\")\" \";\n",
        "    }\n",
        "</style>\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      },
      {
       "javascript": [
        "// adapted from https://gist.github.com/magican/5574556\n",
        "\n",
        "function clone_anchor(element) {\n",
        "  // clone link\n",
        "  var h = element.find(\"div.text_cell_render\").find(':header').first();\n",
        "  var a = h.find('a').clone();\n",
        "  var new_a = $(\"<a>\");\n",
        "  new_a.attr(\"href\", a.attr(\"href\"));\n",
        "  // get the text *excluding* the link text, whatever it may be\n",
        "  var hclone = h.clone();\n",
        "  hclone.children().remove();\n",
        "  new_a.text(hclone.text());\n",
        "  return new_a;\n",
        "}\n",
        "\n",
        "function ol_depth(element) {\n",
        "  // get depth of nested ol\n",
        "  var d = 0;\n",
        "  while (element.prop(\"tagName\").toLowerCase() == 'ol') {\n",
        "    d += 1;\n",
        "    element = element.parent();\n",
        "  }\n",
        "  return d;\n",
        "}\n",
        "\n",
        "function table_of_contents(threshold) {\n",
        "  if (threshold === undefined) {\n",
        "    threshold = 4;\n",
        "  }\n",
        "  var cells = IPython.notebook.get_cells();\n",
        "  \n",
        "  var ol = $(\"<ol/>\");\n",
        "  $(\"#toc\").empty().append(ol);\n",
        "  \n",
        "  for (var i=0; i < cells.length; i++) {\n",
        "    var cell = cells[i];\n",
        "    \n",
        "    if (cell.cell_type !== 'heading') continue;\n",
        "    \n",
        "    var level = cell.level;\n",
        "    if (level > threshold) continue;\n",
        "    \n",
        "    var depth = ol_depth(ol);\n",
        "\n",
        "    // walk down levels\n",
        "    for (; depth < level; depth++) {\n",
        "      var new_ol = $(\"<ol/>\");\n",
        "      ol.append(new_ol);\n",
        "      ol = new_ol;\n",
        "    }\n",
        "    // walk up levels\n",
        "    for (; depth > level; depth--) {\n",
        "      ol = ol.parent();\n",
        "    }\n",
        "    //\n",
        "    ol.append(\n",
        "      $(\"<li/>\").append(clone_anchor(cell.element))\n",
        "    );\n",
        "  }\n",
        "\n",
        "  $('#toc-wrapper .header').click(function(){\n",
        "    $('#toc').slideToggle();\n",
        "    $('#toc-wrapper').toggleClass('closed');\n",
        "    if ($('#toc-wrapper').hasClass('closed')){\n",
        "      $('#toc-wrapper .hide-btn').text('[show]');\n",
        "    } else {\n",
        "      $('#toc-wrapper .hide-btn').text('[hide]');\n",
        "    }\n",
        "    return false;\n",
        "  })\n",
        "\n",
        "  $(window).resize(function(){\n",
        "    $('#toc').css({maxHeight: $(window).height() - 200})\n",
        "  })\n",
        "\n",
        "  $(window).trigger('resize')\n",
        "}\n",
        "\n",
        "table_of_contents();\n",
        "\n",
        "\n"
       ],
       "metadata": {},
       "output_type": "display_data"
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Versions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext version_information\n",
      "%version_information numpy, scipy, matplotlib, sympy, pyopencl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The version_information extension is already loaded. To reload it, use:\n",
        "  %reload_ext version_information\n"
       ]
      },
      {
       "html": [
        "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]</td></tr><tr><td>IPython</td><td>1.0.0</td></tr><tr><td>OS</td><td>posix [linux2]</td></tr><tr><td>numpy</td><td>1.5.1</td></tr><tr><td>scipy</td><td>0.9.0</td></tr><tr><td>matplotlib</td><td>1.0.1</td></tr><tr><td>sympy</td><td>0.6.7</td></tr><tr><td>pyopencl</td><td>'module' object has no attribute '__version__'</td></tr><tr><td colspan='2'>Mon Oct 14 12:36:48 2013 CDT</td></tr></table>"
       ],
       "json": [
        "{ \"Software versions\" : [{ \"module\" : \"Python\", \"version\" : \"2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]\" }, { \"module\" : \"IPython\", \"version\" : \"1.0.0\" }, { \"module\" : \"OS\", \"version\" : \"posix [linux2]\" }, { \"module\" : \"numpy\", \"version\" : \"1.5.1\" }, { \"module\" : \"scipy\", \"version\" : \"0.9.0\" }, { \"module\" : \"matplotlib\", \"version\" : \"1.0.1\" }, { \"module\" : \"sympy\", \"version\" : \"0.6.7\" }, { \"module\" : \"pyopencl\", \"version\" : \"'module' object has no attribute '__version__'\" } ] }"
       ],
       "latex": [
        "\\begin{tabular}{|l|l|}\\hline\n",
        "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
        "Python & 2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1] \\\\ \\hline\n",
        "IPython & 1.0.0 \\\\ \\hline\n",
        "OS & posix [linux2] \\\\ \\hline\n",
        "numpy & 1.5.1 \\\\ \\hline\n",
        "scipy & 0.9.0 \\\\ \\hline\n",
        "matplotlib & 1.0.1 \\\\ \\hline\n",
        "sympy & 0.6.7 \\\\ \\hline\n",
        "pyopencl & 'module' object has no attribute '__version__' \\\\ \\hline\n",
        "\\hline \\multicolumn{2}{|l|}{Mon Oct 14 12:36:48 2013 CDT} \\\\ \\hline\n",
        "\\end{tabular}\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "Software versions\n",
        "Python 2.7.2+ (default, Jul 20 2012, 22:15:08) [GCC 4.6.1]\n",
        "IPython 1.0.0\n",
        "OS posix [linux2]\n",
        "numpy 1.5.1\n",
        "scipy 0.9.0\n",
        "matplotlib 1.0.1\n",
        "sympy 0.6.7\n",
        "pyopencl 'module' object has no attribute '__version__'\n",
        "\n",
        "Mon Oct 14 12:36:48 2013 CDT"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as pycl\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.VERSION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(2013, 1)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vCL = pycl.get_cl_header_version()\n",
      "print \"OpenCL version {}.{}\".format(vCL[0],vCL[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "OpenCL version 1.1\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exploring your GPU device."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Platform"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "platforms = pycl.get_platforms()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs = []\n",
      "for pl in platforms:\n",
      "    print pl.name\n",
      "    print pl.version\n",
      "    print pl.vendor\n",
      "    print pl.extensions\n",
      "    print pl.profile\n",
      "    print '______________'\n",
      "    print '              '\n",
      "    devs.append(pl.get_devices()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NVIDIA CUDA\n",
        "OpenCL 1.1 CUDA 4.2.1\n",
        "NVIDIA Corporation\n",
        "cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll \n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n",
        "AMD Accelerated Parallel Processing\n",
        "OpenCL 1.2 AMD-APP (1113.2)\n",
        "Advanced Micro Devices, Inc.\n",
        "cl_khr_icd cl_amd_event_callback cl_amd_offline_devices\n",
        "FULL_PROFILE\n",
        "______________\n",
        "              \n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=devs[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a.platform.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "'NVIDIA CUDA'"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Devices and properties"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for device in devs:\n",
      "        print(\"---------------------------------------------------------------\")\n",
      "        print(\"Device name:\", device.name)\n",
      "        print(\"Device type:\", pycl.device_type.to_string(device.type))\n",
      "        print(\"Device memory: \", device.global_mem_size//1024//1024, 'MB')\n",
      "        print(\"Device max clock speed:\", device.max_clock_frequency, 'MHz')\n",
      "        print(\"Device compute units:\", device.max_compute_units)\n",
      "        print(\"Device max work group size:\", device.max_work_group_size)\n",
      "        if device.platform.name =='NVIDIA CUDA':\n",
      "            print(\"Device warp size:\", device.warp_size_nv)\n",
      "        print(\"====== IMAGE ======\")\n",
      "        print('Device image support:', device.image_support)\n",
      "        print('Device image 2D max dimensions: [', device.image2d_max_height,',',device.image2d_max_width,']')\n",
      "        print('Device image 3D max dimensions: [', device.image3d_max_height,',',device.image3d_max_width,',',device.image3d_max_depth,']')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---------------------------------------------------------------\n",
        "('Device name:', 'GeForce GTX 670')\n",
        "('Device type:', 'GPU')\n",
        "('Device memory: ', 2047, 'MB')\n",
        "('Device max clock speed:', 980, 'MHz')\n",
        "('Device compute units:', 7)\n",
        "('Device max work group size:', 1024)\n",
        "('Device warp size:', 32)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 32768, ',', 32768, ']')\n",
        "('Device image 3D max dimensions: [', 4096, ',', 4096, ',', 4096, ']')\n",
        "---------------------------------------------------------------\n",
        "('Device name:', 'AMD FX(tm)-8150 Eight-Core Processor           ')\n",
        "('Device type:', 'CPU')\n",
        "('Device memory: ', 7983, 'MB')\n",
        "('Device max clock speed:', 1400, 'MHz')\n",
        "('Device compute units:', 8)\n",
        "('Device max work group size:', 1024)\n",
        "====== IMAGE ======\n",
        "('Device image support:', 1)\n",
        "('Device image 2D max dimensions: [', 8192, ',', 8192, ']')\n",
        "('Device image 3D max dimensions: [', 2048, ',', 2048, ',', 2048, ']')\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devs[0].double_fp_config"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "63"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Context and Arrays"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Default Context"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ctx = pycl.create_some_context()\n",
      "queue = pycl.CommandQueue(ctx)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Choose platform:\n",
        "[0] <pyopencl.Platform 'NVIDIA CUDA' at 0x2482be0>\n",
        "[1] <pyopencl.Platform 'AMD Accelerated Parallel Processing' at 0x7f4f9b4374e0>\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dtype = np.float32\n",
      "N = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl.array as cl_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These alredy in GPU Device (Default: device = 0)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu = cl_array.to_device(queue, np.random.rand(N).astype(dtype))\n",
      "b_gpu = cl_array.to_device(queue, np.random.rand(N).astype(dtype))\n",
      "c_gpu = cl_array.to_device(queue, np.random.rand(N).astype(dtype))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "  \u00b4a_gpu\u00b4 is a special data struct that manage numpy type array in the Device. This is a powerful tool shuch as we can use these structures as the classic numpy case (formally these data is a map in the DEVICE). This data structure is called ARRAY and is different from the linear mem alloc of OpenCL."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.context"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "<pyopencl.Context at 0x7f4f9c901e10 on <pyopencl.Device 'GeForce GTX 670' on 'NVIDIA CUDA' at 0x2602eb0>>"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "<pyopencl._cl.Buffer at 0x283b520>"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.get_sizes(queue)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "((32,), (32,))"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "dtype('float32')"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a_gpu.view"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<bound method Array.view of array([ 0.44539696,  0.00406522,  0.0076884 ,  0.7044642 ,  0.82340962,\n",
        "        0.70948941,  0.01594804,  0.00633587,  0.20782931,  0.94952172], dtype=float32)>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This class of array structures in DEVICE have many operation declare (All in parallel form)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "(a_gpu+b_gpu).view"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<bound method Array.view of array([ 1.30267787,  0.13260771,  0.02158843,  0.85590726,  1.0577271 ,\n",
        "        1.66571283,  0.97340375,  0.2916207 ,  0.9677906 ,  1.39449346], dtype=float32)>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pycl.characterize.usable_local_mem_size(devs[0], nargs=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "49152"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}